// Vitest Snapshot v1, https://vitest.dev/guide/snapshot.html

exports[`Assets Directory Snapshots > CDK assets > cdk/cdk/.prettierrc should match snapshot 1`] = `
"{
  "trailingComma": "es5",
  "printWidth": 120,
  "tabWidth": 2,
  "semi": true,
  "singleQuote": true,
  "arrowParens": "avoid"
}
"
`;

exports[`Assets Directory Snapshots > CDK assets > cdk/cdk/README.md should match snapshot 1`] = `
"# AgentCore CDK Project

This CDK project is managed by the AgentCore CLI. It deploys your agent infrastructure into AWS using the \`@aws/agentcore-cdk\` L3 constructs.

## Structure

- \`bin/cdk.ts\` — Entry point. Reads project configuration from \`agentcore/\` and creates a stack per deployment target.
- \`lib/cdk-stack.ts\` — Defines \`AgentCoreStack\`, which wraps the \`AgentCoreApplication\` L3 construct.
- \`test/cdk.test.ts\` — Unit tests for stack synthesis.

## Useful commands

- \`npm run build\` compile TypeScript to JavaScript
- \`npm run test\` run unit tests
- \`npx cdk synth\` emit the synthesized CloudFormation template
- \`npx cdk deploy\` deploy this stack to your default AWS account/region
- \`npx cdk diff\` compare deployed stack with current state

## Usage

You typically don't need to interact with this directory directly. The AgentCore CLI handles synthesis and deployment:

\`\`\`bash
agentcore deploy    # synthesizes and deploys via CDK
agentcore status    # checks deployment status
\`\`\`
"
`;

exports[`Assets Directory Snapshots > CDK assets > cdk/cdk/bin/cdk.ts should match snapshot 1`] = `
"#!/usr/bin/env node
import { AgentCoreStack } from '../lib/cdk-stack';
import { ConfigIO, type AwsDeploymentTarget } from '@aws/agentcore-cdk';
import { App, type Environment } from 'aws-cdk-lib';
import * as path from 'path';

function toEnvironment(target: AwsDeploymentTarget): Environment {
  return {
    account: target.account,
    region: target.region,
  };
}

function toStackName(projectName: string, targetName: string): string {
  return \`AgentCore-\${projectName}-\${targetName}\`;
}

async function main() {
  // Config root is parent of cdk/ directory. The CLI sets process.cwd() to agentcore/cdk/.
  const configRoot = path.resolve(process.cwd(), '..');
  const configIO = new ConfigIO({ baseDir: configRoot });

  const spec = await configIO.readProjectSpec();
  const targets = await configIO.readAWSDeploymentTargets();

  if (targets.length === 0) {
    throw new Error('No deployment targets configured. Please define targets in agentcore/aws-targets.json');
  }

  const app = new App();

  for (const target of targets) {
    const env = toEnvironment(target);
    const stackName = toStackName(spec.name, target.name);

    new AgentCoreStack(app, stackName, {
      spec,
      env,
      description: \`AgentCore stack for \${spec.name} deployed to \${target.name} (\${target.region})\`,
      tags: {
        'agentcore:project-name': spec.name,
        'agentcore:target-name': target.name,
      },
    });
  }

  app.synth();
}

main();
"
`;

exports[`Assets Directory Snapshots > CDK assets > cdk/cdk/cdk.json should match snapshot 1`] = `
"{
  "app": "node dist/bin/cdk.js",
  "watch": {
    "include": ["**"],
    "exclude": ["README.md", "cdk*.json", "tsconfig.json", "package*.json", "yarn.lock", "node_modules", "dist", "test"]
  },
  "context": {
    "@aws-cdk/aws-signer:signingProfileNamePassedToCfn": true,
    "@aws-cdk/aws-ecs-patterns:secGroupsDisablesImplicitOpenListener": true,
    "@aws-cdk/aws-lambda:recognizeLayerVersion": true,
    "@aws-cdk/core:checkSecretUsage": true,
    "@aws-cdk/core:target-partitions": ["aws", "aws-cn"],
    "@aws-cdk-containers/ecs-service-extensions:enableDefaultLogDriver": true,
    "@aws-cdk/aws-ec2:uniqueImdsv2TemplateName": true,
    "@aws-cdk/aws-ecs:arnFormatIncludesClusterName": true,
    "@aws-cdk/aws-iam:minimizePolicies": true,
    "@aws-cdk/core:validateSnapshotRemovalPolicy": true,
    "@aws-cdk/aws-codepipeline:crossAccountKeyAliasStackSafeResourceName": true,
    "@aws-cdk/aws-s3:createDefaultLoggingPolicy": true,
    "@aws-cdk/aws-sns-subscriptions:restrictSqsDescryption": true,
    "@aws-cdk/aws-apigateway:disableCloudWatchRole": true,
    "@aws-cdk/core:enablePartitionLiterals": true,
    "@aws-cdk/aws-events:eventsTargetQueueSameAccount": true,
    "@aws-cdk/aws-ecs:disableExplicitDeploymentControllerForCircuitBreaker": true,
    "@aws-cdk/aws-iam:importedRoleStackSafeDefaultPolicyName": true,
    "@aws-cdk/aws-s3:serverAccessLogsUseBucketPolicy": true,
    "@aws-cdk/aws-route53-patters:useCertificate": true,
    "@aws-cdk/customresources:installLatestAwsSdkDefault": false,
    "@aws-cdk/aws-rds:databaseProxyUniqueResourceName": true,
    "@aws-cdk/aws-codedeploy:removeAlarmsFromDeploymentGroup": true,
    "@aws-cdk/aws-apigateway:authorizerChangeDeploymentLogicalId": true,
    "@aws-cdk/aws-ec2:launchTemplateDefaultUserData": true,
    "@aws-cdk/aws-secretsmanager:useAttachedSecretResourcePolicyForSecretTargetAttachments": true,
    "@aws-cdk/aws-redshift:columnId": true,
    "@aws-cdk/aws-stepfunctions-tasks:enableEmrServicePolicyV2": true,
    "@aws-cdk/aws-ec2:restrictDefaultSecurityGroup": true,
    "@aws-cdk/aws-apigateway:requestValidatorUniqueId": true,
    "@aws-cdk/aws-kms:aliasNameRef": true,
    "@aws-cdk/aws-kms:applyImportedAliasPermissionsToPrincipal": true,
    "@aws-cdk/aws-autoscaling:generateLaunchTemplateInsteadOfLaunchConfig": true,
    "@aws-cdk/core:includePrefixInUniqueNameGeneration": true,
    "@aws-cdk/aws-efs:denyAnonymousAccess": true,
    "@aws-cdk/aws-opensearchservice:enableOpensearchMultiAzWithStandby": true,
    "@aws-cdk/aws-lambda-nodejs:useLatestRuntimeVersion": true,
    "@aws-cdk/aws-efs:mountTargetOrderInsensitiveLogicalId": true,
    "@aws-cdk/aws-rds:auroraClusterChangeScopeOfInstanceParameterGroupWithEachParameters": true,
    "@aws-cdk/aws-appsync:useArnForSourceApiAssociationIdentifier": true,
    "@aws-cdk/aws-rds:preventRenderingDeprecatedCredentials": true,
    "@aws-cdk/aws-codepipeline-actions:useNewDefaultBranchForCodeCommitSource": true,
    "@aws-cdk/aws-cloudwatch-actions:changeLambdaPermissionLogicalIdForLambdaAction": true,
    "@aws-cdk/aws-codepipeline:crossAccountKeysDefaultValueToFalse": true,
    "@aws-cdk/aws-codepipeline:defaultPipelineTypeToV2": true,
    "@aws-cdk/aws-kms:reduceCrossAccountRegionPolicyScope": true,
    "@aws-cdk/aws-eks:nodegroupNameAttribute": true,
    "@aws-cdk/aws-ec2:ebsDefaultGp3Volume": true,
    "@aws-cdk/aws-ecs:removeDefaultDeploymentAlarm": true,
    "@aws-cdk/custom-resources:logApiResponseDataPropertyTrueDefault": false,
    "@aws-cdk/aws-s3:keepNotificationInImportedBucket": false,
    "@aws-cdk/core:explicitStackTags": true,
    "@aws-cdk/aws-ecs:enableImdsBlockingDeprecatedFeature": false,
    "@aws-cdk/aws-ecs:disableEcsImdsBlocking": true,
    "@aws-cdk/aws-ecs:reduceEc2FargateCloudWatchPermissions": true,
    "@aws-cdk/aws-dynamodb:resourcePolicyPerReplica": true,
    "@aws-cdk/aws-ec2:ec2SumTImeoutEnabled": true,
    "@aws-cdk/aws-appsync:appSyncGraphQLAPIScopeLambdaPermission": true,
    "@aws-cdk/aws-rds:setCorrectValueForDatabaseInstanceReadReplicaInstanceResourceId": true,
    "@aws-cdk/core:cfnIncludeRejectComplexResourceUpdateCreatePolicyIntrinsics": true,
    "@aws-cdk/aws-lambda-nodejs:sdkV3ExcludeSmithyPackages": true,
    "@aws-cdk/aws-stepfunctions-tasks:fixRunEcsTaskPolicy": true,
    "@aws-cdk/aws-ec2:bastionHostUseAmazonLinux2023ByDefault": true,
    "@aws-cdk/aws-route53-targets:userPoolDomainNameMethodWithoutCustomResource": true,
    "@aws-cdk/aws-elasticloadbalancingV2:albDualstackWithoutPublicIpv4SecurityGroupRulesDefault": true,
    "@aws-cdk/aws-iam:oidcRejectUnauthorizedConnections": true,
    "@aws-cdk/core:enableAdditionalMetadataCollection": true,
    "@aws-cdk/aws-lambda:createNewPoliciesWithAddToRolePolicy": false,
    "@aws-cdk/aws-s3:setUniqueReplicationRoleName": true,
    "@aws-cdk/aws-events:requireEventBusPolicySid": true,
    "@aws-cdk/core:aspectPrioritiesMutating": true,
    "@aws-cdk/aws-dynamodb:retainTableReplica": true,
    "@aws-cdk/aws-stepfunctions:useDistributedMapResultWriterV2": true,
    "@aws-cdk/s3-notifications:addS3TrustKeyPolicyForSnsSubscriptions": true,
    "@aws-cdk/aws-ec2:requirePrivateSubnetsForEgressOnlyInternetGateway": true,
    "@aws-cdk/aws-s3:publicAccessBlockedByDefault": true,
    "@aws-cdk/aws-lambda:useCdkManagedLogGroup": true,
    "@aws-cdk/aws-elasticloadbalancingv2:networkLoadBalancerWithSecurityGroupByDefault": true,
    "@aws-cdk/aws-ecs-patterns:uniqueTargetGroupId": true
  }
}
"
`;

exports[`Assets Directory Snapshots > CDK assets > cdk/cdk/gitignore.template should match snapshot 1`] = `
"# Build output
dist/

# Dependencies
node_modules/

# CDK asset staging directory
.cdk.staging
cdk.out
"
`;

exports[`Assets Directory Snapshots > CDK assets > cdk/cdk/jest.config.js should match snapshot 1`] = `
"module.exports = {
  testEnvironment: 'node',
  roots: ['<rootDir>/test'],
  testMatch: ['**/*.test.ts'],
  transform: {
    '^.+\\\\.tsx?$': 'ts-jest',
  },
  setupFilesAfterEnv: ['aws-cdk-lib/testhelpers/jest-autoclean'],
};
"
`;

exports[`Assets Directory Snapshots > CDK assets > cdk/cdk/lib/cdk-stack.ts should match snapshot 1`] = `
"import { AgentCoreApplication, type AgentCoreProjectSpec } from '@aws/agentcore-cdk';
import { CfnOutput, Stack, type StackProps } from 'aws-cdk-lib';
import { Construct } from 'constructs';

export interface AgentCoreStackProps extends StackProps {
  /**
   * The AgentCore project specification containing agents, memories, and credentials.
   */
  spec: AgentCoreProjectSpec;
}

/**
 * CDK Stack that deploys AgentCore infrastructure.
 *
 * This is a thin wrapper that instantiates L3 constructs.
 * All resource logic and outputs are contained within the L3 constructs.
 */
export class AgentCoreStack extends Stack {
  /** The AgentCore application containing all agent environments */
  public readonly application: AgentCoreApplication;

  constructor(scope: Construct, id: string, props: AgentCoreStackProps) {
    super(scope, id, props);

    const { spec } = props;

    // Create AgentCoreApplication with all agents
    this.application = new AgentCoreApplication(this, 'Application', {
      spec,
    });

    // Stack-level output
    new CfnOutput(this, 'StackNameOutput', {
      description: 'Name of the CloudFormation Stack',
      value: this.stackName,
    });
  }
}
"
`;

exports[`Assets Directory Snapshots > CDK assets > cdk/cdk/npmignore.template should match snapshot 1`] = `
"*.ts
!*.d.ts

# CDK asset staging directory
.cdk.staging
cdk.out
"
`;

exports[`Assets Directory Snapshots > CDK assets > cdk/cdk/package.json should match snapshot 1`] = `
"{
  "name": "agentcore-cdk-app",
  "version": "0.1.0",
  "bin": {
    "cdk": "dist/bin/cdk.js"
  },
  "scripts": {
    "build": "tsc",
    "watch": "tsc -w",
    "test": "jest",
    "cdk": "npm run build && cdk",
    "clean": "rm -rf dist",
    "format": "prettier --write .",
    "format:check": "prettier --check ."
  },
  "devDependencies": {
    "@types/jest": "^29.5.14",
    "@types/node": "^24.10.1",
    "jest": "^29.7.0",
    "ts-jest": "^29.2.5",
    "aws-cdk": "2.1100.1",
    "prettier": "^3.4.2",
    "typescript": "~5.9.3"
  },
  "dependencies": {
    "@aws/agentcore-cdk": "^0.1.0-alpha.1",
    "aws-cdk-lib": "2.234.1",
    "constructs": "^10.0.0"
  }
}
"
`;

exports[`Assets Directory Snapshots > CDK assets > cdk/cdk/test/cdk.test.ts should match snapshot 1`] = `
"import * as cdk from 'aws-cdk-lib';
import { Template } from 'aws-cdk-lib/assertions';
import { AgentCoreStack } from '../lib/cdk-stack';

test('AgentCoreStack synthesizes with empty spec', () => {
  const app = new cdk.App();
  const stack = new AgentCoreStack(app, 'TestStack', {
    spec: {
      name: 'testproject',
      version: 1,
      agents: [],
      memories: [],
      credentials: [],
    },
  });
  const template = Template.fromStack(stack);
  template.hasOutput('StackNameOutput', {
    Description: 'Name of the CloudFormation Stack',
  });
});
"
`;

exports[`Assets Directory Snapshots > CDK assets > cdk/cdk/tsconfig.json should match snapshot 1`] = `
"{
  "compilerOptions": {
    "target": "ES2022",
    "module": "CommonJS",
    "moduleResolution": "Node",
    "lib": ["es2022"],
    "declaration": true,
    "strict": true,
    "noImplicitAny": true,
    "strictNullChecks": true,
    "noImplicitThis": true,
    "alwaysStrict": true,
    "noUnusedLocals": false,
    "noUnusedParameters": false,
    "noImplicitReturns": true,
    "noFallthroughCasesInSwitch": false,
    "inlineSourceMap": true,
    "inlineSources": true,
    "experimentalDecorators": true,
    "strictPropertyInitialization": false,
    "skipLibCheck": true,
    "typeRoots": ["./node_modules/@types"],
    "rootDir": ".",
    "outDir": "dist"
  },
  "include": ["bin/**/*", "lib/**/*", "test/**/*"],
  "exclude": ["node_modules", "cdk.out", "dist"]
}
"
`;

exports[`Assets Directory Snapshots > File listing > should match the expected file structure > asset-file-listing 1`] = `
[
  "AGENTS.md",
  "README.md",
  "agents/AGENTS.md",
  "cdk/.prettierrc",
  "cdk/README.md",
  "cdk/bin/cdk.ts",
  "cdk/cdk.json",
  "cdk/gitignore.template",
  "cdk/jest.config.js",
  "cdk/lib/cdk-stack.ts",
  "cdk/npmignore.template",
  "cdk/package.json",
  "cdk/test/cdk.test.ts",
  "cdk/tsconfig.json",
  "container/python/Dockerfile",
  "container/python/dockerignore.template",
  "mcp/python-lambda/README.md",
  "mcp/python-lambda/handler.py",
  "mcp/python-lambda/pyproject.toml",
  "mcp/python/README.md",
  "mcp/python/pyproject.toml",
  "mcp/python/server.py",
  "python/autogen/base/README.md",
  "python/autogen/base/gitignore.template",
  "python/autogen/base/main.py",
  "python/autogen/base/mcp_client/__init__.py",
  "python/autogen/base/mcp_client/client.py",
  "python/autogen/base/model/__init__.py",
  "python/autogen/base/model/load.py",
  "python/autogen/base/pyproject.toml",
  "python/crewai/base/README.md",
  "python/crewai/base/gitignore.template",
  "python/crewai/base/main.py",
  "python/crewai/base/model/__init__.py",
  "python/crewai/base/model/load.py",
  "python/crewai/base/pyproject.toml",
  "python/googleadk/base/README.md",
  "python/googleadk/base/gitignore.template",
  "python/googleadk/base/main.py",
  "python/googleadk/base/mcp_client/__init__.py",
  "python/googleadk/base/mcp_client/client.py",
  "python/googleadk/base/model/__init__.py",
  "python/googleadk/base/model/load.py",
  "python/googleadk/base/pyproject.toml",
  "python/langchain_langgraph/base/README.md",
  "python/langchain_langgraph/base/gitignore.template",
  "python/langchain_langgraph/base/main.py",
  "python/langchain_langgraph/base/mcp_client/__init__.py",
  "python/langchain_langgraph/base/mcp_client/client.py",
  "python/langchain_langgraph/base/model/__init__.py",
  "python/langchain_langgraph/base/model/load.py",
  "python/langchain_langgraph/base/pyproject.toml",
  "python/openaiagents/base/README.md",
  "python/openaiagents/base/gitignore.template",
  "python/openaiagents/base/main.py",
  "python/openaiagents/base/mcp_client/__init__.py",
  "python/openaiagents/base/mcp_client/client.py",
  "python/openaiagents/base/model/__init__.py",
  "python/openaiagents/base/model/load.py",
  "python/openaiagents/base/pyproject.toml",
  "python/strands/base/README.md",
  "python/strands/base/gitignore.template",
  "python/strands/base/main.py",
  "python/strands/base/mcp_client/__init__.py",
  "python/strands/base/mcp_client/client.py",
  "python/strands/base/model/__init__.py",
  "python/strands/base/model/load.py",
  "python/strands/base/pyproject.toml",
  "python/strands/capabilities/memory/__init__.py",
  "python/strands/capabilities/memory/session.py",
  "typescript/.gitkeep",
]
`;

exports[`Assets Directory Snapshots > MCP assets > mcp/mcp/python/README.md should match snapshot 1`] = `
"# {{ name }}

This is a template MCP server generated by the AgentCore CLI.

Demonstrates HTTP tool patterns with proper error handling and retry logic.

## Quick Start

\`\`\`bash
# Create and activate virtual environment
uv venv
source .venv/bin/activate  # or .venv\\Scripts\\activate on Windows

# Install dependencies
uv sync

# Run the server
uv run server.py
\`\`\`

## Available Tools

| Tool              | Description                                            |
| ----------------- | ------------------------------------------------------ |
| \`lookup_ip\`       | Look up geolocation and network info for an IP address |
| \`get_random_user\` | Generate a random user profile for testing             |
| \`fetch_post\`      | Fetch a post by ID from JSONPlaceholder API            |
"
`;

exports[`Assets Directory Snapshots > MCP assets > mcp/mcp/python/pyproject.toml should match snapshot 1`] = `
"[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[project]
name = "{{ name }}"
version = "0.1.0"
description = "MCP Server demonstrating HTTP tool patterns"
readme = "README.md"
requires-python = ">=3.10"
dependencies = [
    "mcp[cli] >= 1.2.0",
    "httpx >= 0.27.0",
    "opentelemetry-distro",
    "opentelemetry-exporter-otlp",
]

[project.scripts]
server = "server:main"

[tool.hatch.build.targets.wheel]
packages = ["."]
"
`;

exports[`Assets Directory Snapshots > MCP assets > mcp/mcp/python/server.py should match snapshot 1`] = `
""""
MCP Server demonstrating HTTP tool patterns.

This template shows:
- Async HTTP boundaries with proper error handling
- Retry logic and partial failure
- Response parsing and validation

Run with: uv run server.py
"""

import logging
from typing import Any

import httpx
from mcp.server.fastmcp import FastMCP

logging.basicConfig(level=logging.INFO, format="%(levelname)s - %(message)s")
logger = logging.getLogger(__name__)

mcp = FastMCP("tools")

HTTP_TIMEOUT = 10.0
MAX_RETRIES = 2


async def fetch_json(url: str, headers: dict[str, str] | None = None) -> dict[str, Any] | None:
    """Make an HTTP GET request with retry logic."""
    async with httpx.AsyncClient() as client:
        for attempt in range(MAX_RETRIES):
            try:
                response = await client.get(url, headers=headers, timeout=HTTP_TIMEOUT)
                response.raise_for_status()
                return response.json()
            except httpx.TimeoutException:
                logger.warning(f"Timeout on attempt {attempt + 1} for {url}")
            except httpx.HTTPStatusError as e:
                logger.error(f"HTTP {e.response.status_code} for {url}")
                return None
            except httpx.RequestError as e:
                logger.error(f"Request failed: {e}")
                return None
    return None


@mcp.tool()
async def lookup_ip(ip_address: str) -> str:
    """Look up geolocation and network info for an IP address.

    Args:
        ip_address: IPv4 or IPv6 address to look up
    """
    data = await fetch_json(f"http://ip-api.com/json/{ip_address}")

    if not data:
        return f"Failed to look up IP: {ip_address}"

    if data.get("status") == "fail":
        return f"Lookup failed: {data.get('message', 'unknown error')}"

    return (
        f"IP: {data['query']}\\n"
        f"Location: {data['city']}, {data['regionName']}, {data['country']}\\n"
        f"ISP: {data['isp']}\\n"
        f"Organization: {data['org']}\\n"
        f"Timezone: {data['timezone']}"
    )


@mcp.tool()
async def get_random_user() -> str:
    """Generate a random user profile for testing or mock data."""
    data = await fetch_json("https://randomuser.me/api/")

    if not data or "results" not in data:
        return "Failed to generate random user."

    user = data["results"][0]
    name = user["name"]
    location = user["location"]

    return (
        f"Name: {name['first']} {name['last']}\\n"
        f"Email: {user['email']}\\n"
        f"Location: {location['city']}, {location['country']}\\n"
        f"Phone: {user['phone']}"
    )


@mcp.tool()
async def fetch_post(post_id: int) -> str:
    """Fetch a post by ID from JSONPlaceholder API.

    Args:
        post_id: The post ID (1-100)
    """
    if not 1 <= post_id <= 100:
        return "Post ID must be between 1 and 100."

    data = await fetch_json(f"https://jsonplaceholder.typicode.com/posts/{post_id}")

    if not data:
        return f"Failed to fetch post {post_id}."

    return (
        f"Post #{data['id']}\\n"
        f"Title: {data['title']}\\n\\n"
        f"{data['body']}"
    )


def main():
    mcp.run(transport="stdio")


if __name__ == "__main__":
    main()
"
`;

exports[`Assets Directory Snapshots > MCP assets > mcp/mcp/python-lambda/README.md should match snapshot 1`] = `
"# {{ Name }}

Lambda-based tools for AgentCore Gateway.

## Tools

- \`lookup_ip\` - Look up geolocation for an IP address
- \`get_random_user\` - Generate random user profile
- \`fetch_post\` - Fetch a post by ID

## Gateway Integration

Tools are invoked via AgentCore Gateway. The tool name is passed in:
\`context.client_context.custom["bedrockAgentCoreToolName"]\`

Format: \`{target_name}___{tool_name}\`

## Adding New Tools

1. Define the tool function with the \`@tool("tool_name")\` decorator
2. Add the tool definition to \`mcp-defs.json\` in your agentcore project
3. The tool will be automatically routed by the handler
"
`;

exports[`Assets Directory Snapshots > MCP assets > mcp/mcp/python-lambda/handler.py should match snapshot 1`] = `
""""
Lambda handler for AgentCore Gateway tools.

This template mirrors the FastMCP server tools but runs as a Lambda function
behind an AgentCore Gateway.

Tool routing uses bedrockAgentCoreToolName from client context:
  Format: {target_name}___{tool_name}
"""
import json
import logging
import urllib.request
import urllib.error
from typing import Any, Dict, Optional

logger = logging.getLogger()
logger.setLevel(logging.INFO)

HTTP_TIMEOUT = 10
TOOLS = {}


def tool(name: str):
    """Decorator to register a tool handler."""
    def decorator(func):
        TOOLS[name] = func
        return func
    return decorator


def lambda_handler(event: Dict[str, Any], context) -> Dict[str, Any]:
    """Route incoming gateway requests to the appropriate tool."""
    try:
        extended_name = context.client_context.custom.get("bedrockAgentCoreToolName", "")
        tool_name = None

        if "___" in extended_name:
            tool_name = extended_name.split("___", 1)[1]

        if not tool_name:
            return _response(400, {"error": "Missing tool name in bedrockAgentCoreToolName"})

        handler = TOOLS.get(tool_name)
        if not handler:
            return _response(400, {"error": f"Unknown tool: {tool_name}"})

        result = handler(event)
        return _response(200, {"result": result})

    except Exception as e:
        logger.exception("Tool execution failed")
        return _response(500, {"error": str(e)})


def _response(status_code: int, body: Dict[str, Any]) -> Dict[str, Any]:
    """Consistent JSON response wrapper."""
    return {"statusCode": status_code, "body": json.dumps(body)}


def _fetch_json(url: str) -> Optional[Dict[str, Any]]:
    """Fetch JSON from URL with error handling."""
    try:
        req = urllib.request.Request(url, headers={"User-Agent": "AgentCore-Tool/1.0"})
        with urllib.request.urlopen(req, timeout=HTTP_TIMEOUT) as resp:
            return json.loads(resp.read().decode())
    except (urllib.error.URLError, json.JSONDecodeError) as e:
        logger.warning(f"Failed to fetch {url}: {e}")
        return None


@tool("{{Name}}_lookup_ip")
def lookup_ip(event: Dict[str, Any]) -> str:
    """Look up geolocation and network info for an IP address.

    Args:
        ip_address: IPv4 or IPv6 address to look up
    """
    ip_address = event.get("ip_address", "")
    if not ip_address:
        return "Missing required parameter: ip_address"

    data = _fetch_json(f"http://ip-api.com/json/{ip_address}")
    if not data:
        return f"Failed to look up IP: {ip_address}"

    if data.get("status") == "fail":
        return f"Lookup failed: {data.get('message', 'unknown error')}"

    return (
        f"IP: {data['query']}\\n"
        f"Location: {data['city']}, {data['regionName']}, {data['country']}\\n"
        f"ISP: {data['isp']}\\n"
        f"Organization: {data['org']}\\n"
        f"Timezone: {data['timezone']}"
    )


@tool("{{Name}}_get_random_user")
def get_random_user(event: Dict[str, Any]) -> str:
    """Generate a random user profile for testing or mock data."""
    data = _fetch_json("https://randomuser.me/api/")
    if not data or "results" not in data:
        return "Failed to generate random user."

    user = data["results"][0]
    name = user["name"]
    location = user["location"]

    return (
        f"Name: {name['first']} {name['last']}\\n"
        f"Email: {user['email']}\\n"
        f"Location: {location['city']}, {location['country']}\\n"
        f"Phone: {user['phone']}"
    )


@tool("{{Name}}_fetch_post")
def fetch_post(event: Dict[str, Any]) -> str:
    """Fetch a post by ID from JSONPlaceholder API.

    Args:
        post_id: The post ID (1-100)
    """
    post_id = event.get("post_id")
    if post_id is None:
        return "Missing required parameter: post_id"

    try:
        post_id = int(post_id)
    except (TypeError, ValueError):
        return "post_id must be an integer"

    if not 1 <= post_id <= 100:
        return "Post ID must be between 1 and 100."

    data = _fetch_json(f"https://jsonplaceholder.typicode.com/posts/{post_id}")
    if not data:
        return f"Failed to fetch post {post_id}."

    return (
        f"Post #{data['id']}\\n"
        f"Title: {data['title']}\\n\\n"
        f"{data['body']}"
    )
"
`;

exports[`Assets Directory Snapshots > MCP assets > mcp/mcp/python-lambda/pyproject.toml should match snapshot 1`] = `
"[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[project]
name = "{{ name }}"
version = "0.1.0"
description = "Lambda tools for AgentCore Gateway"
readme = "README.md"
requires-python = ">=3.10"
# No external dependencies - uses stdlib only
dependencies = []

[tool.hatch.build.targets.wheel]
packages = ["."]
"
`;

exports[`Assets Directory Snapshots > Python framework assets > python/python/autogen/base/README.md should match snapshot 1`] = `
"This is a project generated by the agentcore create CLI tool!

# Layout

The generated application code lives at the agent root directory. At the root, there is a \`.gitignore\` file, an
\`agentcore/\` folder which represents the configurations and state associated with this project. Other \`agentcore\`
commands like \`deploy\`, \`dev\`, and \`invoke\` rely on the configuration stored here.

## Agent Root

The main entrypoint to your app is defined in \`main.py\`. Using the AgentCore SDK \`@app.entrypoint\` decorator, this
file defines a Starlette ASGI app with the AutoGen framework running within.

\`model/load.py\` instantiates your chosen model provider.

## Environment Variables

| Variable | Required | Description |
| --- | --- | --- |
{{#if hasIdentity}}| \`{{identityProviders.[0].envVarName}}\` | Yes | {{modelProvider}} API key (local) or Identity provider name (deployed) |
{{/if}}| \`LOCAL_DEV\` | No | Set to \`1\` to use \`.env.local\` instead of AgentCore Identity |

# Developing locally

If installation was successful, a virtual environment is already created with dependencies installed.

Run \`source .venv/bin/activate\` before developing.

\`agentcore dev\` will start a local server on 0.0.0.0:8080.

In a new terminal, you can invoke that server with:

\`agentcore invoke --dev "What can you do"\`

# Deployment

After providing credentials, \`agentcore deploy\` will deploy your project into Amazon Bedrock AgentCore.

Use \`agentcore invoke\` to invoke your deployed agent.
"
`;

exports[`Assets Directory Snapshots > Python framework assets > python/python/autogen/base/gitignore.template should match snapshot 1`] = `
"# Environment variables
.env

# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg

# Virtual environments
.venv/
venv/
ENV/
env/

# IDE
.vscode/
.idea/
*.swp
*.swo
*~

# OS
.DS_Store
Thumbs.db
"
`;

exports[`Assets Directory Snapshots > Python framework assets > python/python/autogen/base/main.py should match snapshot 1`] = `
"import os
from autogen_agentchat.agents import AssistantAgent
from autogen_core.tools import FunctionTool
from bedrock_agentcore.runtime import BedrockAgentCoreApp
from model.load import load_model
from mcp_client.client import get_streamable_http_mcp_tools

app = BedrockAgentCoreApp()
log = app.logger


# Define a simple function tool
def add_numbers(a: int, b: int) -> int:
    """Return the sum of two numbers"""
    return a + b


add_numbers_tool = FunctionTool(
    add_numbers, description="Return the sum of two numbers"
)

# Define a collection of tools used by the model
tools = [add_numbers_tool]


@app.entrypoint
async def invoke(payload, context):
    log.info("Invoking Agent.....")

    # Get MCP Tools
    mcp_tools = await get_streamable_http_mcp_tools()

    # Define an AssistantAgent with the model and tools
    agent = AssistantAgent(
        name="{{ name }}",
        model_client=load_model(),
        tools=tools + mcp_tools,
        system_message="You are a helpful assistant. Use tools when appropriate.",
    )

    # Process the user prompt
    prompt = payload.get("prompt", "What can you help me with?")

    # Run the agent
    result = await agent.run(task=prompt)

    # Return result
    return {"result": result.messages[-1].content}


if __name__ == "__main__":
    app.run()
"
`;

exports[`Assets Directory Snapshots > Python framework assets > python/python/autogen/base/mcp_client/__init__.py should match snapshot 1`] = `
"# Package marker
"
`;

exports[`Assets Directory Snapshots > Python framework assets > python/python/autogen/base/mcp_client/client.py should match snapshot 1`] = `
"from typing import List
from autogen_ext.tools.mcp import (
    StreamableHttpMcpToolAdapter,
    StreamableHttpServerParams,
    mcp_server_tools,
)

# ExaAI provides information about code through web searches, crawling and code context searches through their platform. Requires no authentication
EXAMPLE_MCP_ENDPOINT = "https://mcp.exa.ai/mcp"


async def get_streamable_http_mcp_tools() -> List[StreamableHttpMcpToolAdapter]:
    """
    Returns MCP Tools compatible with AutoGen.
    """
    # to use an MCP server that supports bearer authentication, add headers={"Authorization": f"Bearer {access_token}"}
    server_params = StreamableHttpServerParams(url=EXAMPLE_MCP_ENDPOINT)
    return await mcp_server_tools(server_params)
"
`;

exports[`Assets Directory Snapshots > Python framework assets > python/python/autogen/base/model/__init__.py should match snapshot 1`] = `
"# Package marker
"
`;

exports[`Assets Directory Snapshots > Python framework assets > python/python/autogen/base/model/load.py should match snapshot 1`] = `
"{{#if (eq modelProvider "Bedrock")}}
import os
from autogen_ext.models.anthropic import AnthropicBedrockChatCompletionClient
from autogen_core.models import ModelInfo, ModelFamily

# Uses global inference profile for Claude Sonnet 4.5
# https://docs.aws.amazon.com/bedrock/latest/userguide/inference-profiles-support.html
MODEL_ID = "global.anthropic.claude-sonnet-4-5-20250929-v1:0"


def load_model() -> AnthropicBedrockChatCompletionClient:
    """Get Bedrock model client using IAM credentials."""
    return AnthropicBedrockChatCompletionClient(
        model=MODEL_ID,
        model_info=ModelInfo(
            vision=False,
            function_calling=True,
            json_output=False,
            family=ModelFamily.CLAUDE_4_SONNET,
            structured_output=True
        ),
        bedrock_info={"aws_region": os.environ.get("AWS_REGION", "us-east-1")}
    )
{{/if}}
{{#if (eq modelProvider "Anthropic")}}
import os
from autogen_ext.models.anthropic import AnthropicChatCompletionClient
from bedrock_agentcore.identity.auth import requires_api_key

IDENTITY_PROVIDER_NAME = "{{identityProviders.[0].name}}"
IDENTITY_ENV_VAR = "{{identityProviders.[0].envVarName}}"


@requires_api_key(provider_name=IDENTITY_PROVIDER_NAME)
def _agentcore_identity_api_key_provider(api_key: str) -> str:
    """Fetch API key from AgentCore Identity."""
    return api_key


def _get_api_key() -> str:
    """
    Uses AgentCore Identity for API key management in deployed environments.
    For local development, run via 'agentcore dev' which loads agentcore/.env.
    """
    if os.getenv("LOCAL_DEV") == "1":
        api_key = os.getenv(IDENTITY_ENV_VAR)
        if not api_key:
            raise RuntimeError(
                f"{IDENTITY_ENV_VAR} not found. Add {IDENTITY_ENV_VAR}=your-key to .env.local"
            )
        return api_key
    return _agentcore_identity_api_key_provider()


def load_model() -> AnthropicChatCompletionClient:
    """Get authenticated Anthropic model client."""
    return AnthropicChatCompletionClient(
        model="claude-sonnet-4-5-20250929",
        api_key=_get_api_key()
    )
{{/if}}
{{#if (eq modelProvider "OpenAI")}}
import os
from autogen_ext.models.openai import OpenAIChatCompletionClient
from bedrock_agentcore.identity.auth import requires_api_key

IDENTITY_PROVIDER_NAME = "{{identityProviders.[0].name}}"
IDENTITY_ENV_VAR = "{{identityProviders.[0].envVarName}}"


@requires_api_key(provider_name=IDENTITY_PROVIDER_NAME)
def _agentcore_identity_api_key_provider(api_key: str) -> str:
    """Fetch API key from AgentCore Identity."""
    return api_key


def _get_api_key() -> str:
    """
    Uses AgentCore Identity for API key management in deployed environments.
    For local development, run via 'agentcore dev' which loads agentcore/.env.
    """
    if os.getenv("LOCAL_DEV") == "1":
        api_key = os.getenv(IDENTITY_ENV_VAR)
        if not api_key:
            raise RuntimeError(
                f"{IDENTITY_ENV_VAR} not found. Add {IDENTITY_ENV_VAR}=your-key to .env.local"
            )
        return api_key
    return _agentcore_identity_api_key_provider()


def load_model() -> OpenAIChatCompletionClient:
    """Get authenticated OpenAI model client."""
    return OpenAIChatCompletionClient(
        model="gpt-4o",
        api_key=_get_api_key()
    )
{{/if}}
{{#if (eq modelProvider "Gemini")}}
import os
from autogen_ext.models.openai import OpenAIChatCompletionClient
from bedrock_agentcore.identity.auth import requires_api_key

IDENTITY_PROVIDER_NAME = "{{identityProviders.[0].name}}"
IDENTITY_ENV_VAR = "{{identityProviders.[0].envVarName}}"


@requires_api_key(provider_name=IDENTITY_PROVIDER_NAME)
def _agentcore_identity_api_key_provider(api_key: str) -> str:
    """Fetch API key from AgentCore Identity."""
    return api_key


def _get_api_key() -> str:
    """
    Uses AgentCore Identity for API key management in deployed environments.
    For local development, run via 'agentcore dev' which loads agentcore/.env.
    """
    if os.getenv("LOCAL_DEV") == "1":
        api_key = os.getenv(IDENTITY_ENV_VAR)
        if not api_key:
            raise RuntimeError(
                f"{IDENTITY_ENV_VAR} not found. Add {IDENTITY_ENV_VAR}=your-key to .env.local"
            )
        return api_key
    return _agentcore_identity_api_key_provider()


def load_model() -> OpenAIChatCompletionClient:
    """Get authenticated Gemini model client via OpenAI-compatible API."""
    return OpenAIChatCompletionClient(
        model="gemini-2.0-flash",
        api_key=_get_api_key(),
        base_url="https://generativelanguage.googleapis.com/v1beta/openai/"
    )
{{/if}}
"
`;

exports[`Assets Directory Snapshots > Python framework assets > python/python/autogen/base/pyproject.toml should match snapshot 1`] = `
"[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[project]
name = "{{ name }}"
version = "0.1.0"
description = "AgentCore Runtime Application using AutoGen SDK"
readme = "README.md"
requires-python = ">=3.10"
dependencies = [
    "autogen-agentchat >= 0.7.5",
    "autogen-ext[mcp] >= 0.7.5",
    "opentelemetry-distro",
    "opentelemetry-exporter-otlp",
    "bedrock-agentcore >= 1.0.3",
    "botocore[crt] >= 1.35.0",
    "tiktoken",
{{#if (eq modelProvider "Bedrock")}}
    "autogen-ext[anthropic] >= 0.7.5",
{{/if}}
{{#if (eq modelProvider "Anthropic")}}
    "autogen-ext[anthropic] >= 0.7.5",
{{/if}}
{{#if (eq modelProvider "OpenAI")}}
    "autogen-ext[openai] >= 0.7.5",
{{/if}}
{{#if (eq modelProvider "Gemini")}}
    "autogen-ext[openai] >= 0.7.5",
{{/if}}
]

[tool.hatch.build.targets.wheel]
packages = ["."]
"
`;

exports[`Assets Directory Snapshots > Python framework assets > python/python/crewai/base/README.md should match snapshot 1`] = `
"This is a project generated by the agentcore create CLI tool!

# Layout

The generated application code lives at the agent root directory. At the root, there is a \`.gitignore\` file, an
\`agentcore/\` folder which represents the configurations and state associated with this project. Other \`agentcore\`
commands like \`deploy\`, \`dev\`, and \`invoke\` rely on the configuration stored here.

## Agent Root

The main entrypoint to your app is defined in \`main.py\`. Using the AgentCore SDK \`@app.entrypoint\` decorator, this
file defines a Starlette ASGI app with the CrewAI framework running within.

\`model/load.py\` instantiates your chosen model provider.

## Environment Variables

| Variable | Required | Description |
| --- | --- | --- |
{{#if hasIdentity}}| \`{{identityProviders.[0].envVarName}}\` | Yes | {{modelProvider}} API key (local) or Identity provider name (deployed) |
{{/if}}| \`LOCAL_DEV\` | No | Set to \`1\` to use \`.env.local\` instead of AgentCore Identity |

# Developing locally

If installation was successful, a virtual environment is already created with dependencies installed.

Run \`source .venv/bin/activate\` before developing.

\`agentcore dev\` will start a local server on 0.0.0.0:8080.

In a new terminal, you can invoke that server with:

\`agentcore invoke --dev "What can you do"\`

# Deployment

After providing credentials, \`agentcore deploy\` will deploy your project into Amazon Bedrock AgentCore.

Use \`agentcore invoke\` to invoke your deployed agent.
"
`;

exports[`Assets Directory Snapshots > Python framework assets > python/python/crewai/base/gitignore.template should match snapshot 1`] = `
"# Environment variables
.env

# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg

# Virtual environments
.venv/
venv/
ENV/
env/

# IDE
.vscode/
.idea/
*.swp
*.swo
*~

# OS
.DS_Store
Thumbs.db
"
`;

exports[`Assets Directory Snapshots > Python framework assets > python/python/crewai/base/main.py should match snapshot 1`] = `
"from crewai import Agent, Crew, Task, Process
from crewai.tools import tool
from bedrock_agentcore.runtime import BedrockAgentCoreApp
from model.load import load_model

app = BedrockAgentCoreApp()
log = app.logger


# Define a simple function tool
@tool
def add_numbers(a: int, b: int) -> int:
    """Return the sum of two numbers"""
    return a + b


# Define a collection of tools used by the model
tools = [add_numbers]


@app.entrypoint
def invoke(payload, context):
    log.info("Invoking Agent.....")

    # Define the Agent with Tools
    agent = Agent(
        role="Question Answering Assistant",
        goal="Answer the users questions",
        backstory="Always eager to answer any questions",
        llm=load_model(),
        tools=tools,
    )

    # Define the Task
    task = Task(
        agent=agent,
        description="Answer the users question: {prompt}",
        expected_output="An answer to the users question",
    )

    # Create the Crew
    crew = Crew(agents=[agent], tasks=[task], process=Process.sequential)

    # Process the user prompt
    prompt = payload.get("prompt", "What can you help me with?")

    # Run the crew
    result = crew.kickoff(inputs={"prompt": prompt})

    # Return result
    return {"result": result.raw}


if __name__ == "__main__":
    app.run()
"
`;

exports[`Assets Directory Snapshots > Python framework assets > python/python/crewai/base/model/__init__.py should match snapshot 1`] = `
"# Package marker
"
`;

exports[`Assets Directory Snapshots > Python framework assets > python/python/crewai/base/model/load.py should match snapshot 1`] = `
"{{#if (eq modelProvider "Bedrock")}}
from crewai import LLM

# Uses global inference profile for Claude Sonnet 4.5
# https://docs.aws.amazon.com/bedrock/latest/userguide/inference-profiles-support.html
MODEL_ID = "bedrock/global.anthropic.claude-sonnet-4-5-20250929-v1:0"


def load_model() -> LLM:
    """Get Bedrock model client using IAM credentials."""
    return LLM(model=MODEL_ID)
{{/if}}
{{#if (eq modelProvider "Anthropic")}}
import os
from crewai import LLM
from bedrock_agentcore.identity.auth import requires_api_key

IDENTITY_PROVIDER_NAME = "{{identityProviders.[0].name}}"
IDENTITY_ENV_VAR = "{{identityProviders.[0].envVarName}}"


@requires_api_key(provider_name=IDENTITY_PROVIDER_NAME)
def _agentcore_identity_api_key_provider(api_key: str) -> str:
    """Fetch API key from AgentCore Identity."""
    return api_key


def _get_api_key() -> str:
    """
    Uses AgentCore Identity for API key management in deployed environments.
    For local development, run via 'agentcore dev' which loads agentcore/.env.
    """
    if os.getenv("LOCAL_DEV") == "1":
        api_key = os.getenv(IDENTITY_ENV_VAR)
        if not api_key:
            raise RuntimeError(
                f"{IDENTITY_ENV_VAR} not found. Add {IDENTITY_ENV_VAR}=your-key to .env.local"
            )
        return api_key
    return _agentcore_identity_api_key_provider()


def load_model() -> LLM:
    """Get authenticated Anthropic model client."""
    api_key = _get_api_key()
    # CrewAI requires ANTHROPIC_API_KEY env var (ignores api_key parameter)
    os.environ["ANTHROPIC_API_KEY"] = api_key
    return LLM(
        model="anthropic/claude-sonnet-4-5-20250929",
        api_key=api_key,
        max_tokens=4096
    )
{{/if}}
{{#if (eq modelProvider "OpenAI")}}
import os
from crewai import LLM
from bedrock_agentcore.identity.auth import requires_api_key

IDENTITY_PROVIDER_NAME = "{{identityProviders.[0].name}}"
IDENTITY_ENV_VAR = "{{identityProviders.[0].envVarName}}"


@requires_api_key(provider_name=IDENTITY_PROVIDER_NAME)
def _agentcore_identity_api_key_provider(api_key: str) -> str:
    """Fetch API key from AgentCore Identity."""
    return api_key


def _get_api_key() -> str:
    """
    Uses AgentCore Identity for API key management in deployed environments.
    For local development, run via 'agentcore dev' which loads agentcore/.env.
    """
    if os.getenv("LOCAL_DEV") == "1":
        api_key = os.getenv(IDENTITY_ENV_VAR)
        if not api_key:
            raise RuntimeError(
                f"{IDENTITY_ENV_VAR} not found. Add {IDENTITY_ENV_VAR}=your-key to .env.local"
            )
        return api_key
    return _agentcore_identity_api_key_provider()


def load_model() -> LLM:
    """Get authenticated OpenAI model client."""
    api_key = _get_api_key()
    # CrewAI requires OPENAI_API_KEY env var (ignores api_key parameter)
    os.environ["OPENAI_API_KEY"] = api_key
    return LLM(
        model="openai/gpt-4.1",
        api_key=api_key
    )
{{/if}}
{{#if (eq modelProvider "Gemini")}}
import os
from crewai import LLM
from bedrock_agentcore.identity.auth import requires_api_key

IDENTITY_PROVIDER_NAME = "{{identityProviders.[0].name}}"
IDENTITY_ENV_VAR = "{{identityProviders.[0].envVarName}}"


@requires_api_key(provider_name=IDENTITY_PROVIDER_NAME)
def _agentcore_identity_api_key_provider(api_key: str) -> str:
    """Fetch API key from AgentCore Identity."""
    return api_key


def _get_api_key() -> str:
    """
    Uses AgentCore Identity for API key management in deployed environments.
    For local development, run via 'agentcore dev' which loads agentcore/.env.
    """
    if os.getenv("LOCAL_DEV") == "1":
        api_key = os.getenv(IDENTITY_ENV_VAR)
        if not api_key:
            raise RuntimeError(
                f"{IDENTITY_ENV_VAR} not found. Add {IDENTITY_ENV_VAR}=your-key to .env.local"
            )
        return api_key
    return _agentcore_identity_api_key_provider()


def load_model() -> LLM:
    """Get authenticated Gemini model client."""
    api_key = _get_api_key()
    # CrewAI requires GEMINI_API_KEY env var (ignores api_key parameter)
    os.environ["GEMINI_API_KEY"] = api_key
    return LLM(
        model="gemini/gemini-2.5-flash",
        api_key=api_key
    )
{{/if}}
"
`;

exports[`Assets Directory Snapshots > Python framework assets > python/python/crewai/base/pyproject.toml should match snapshot 1`] = `
"[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[project]
name = "{{ name }}"
version = "0.1.0"
description = "AgentCore Runtime Application using CrewAI SDK"
readme = "README.md"
requires-python = ">=3.11"
dependencies = [
    "opentelemetry-distro",
    "opentelemetry-exporter-otlp",
    "bedrock-agentcore >= 1.0.3",
    "botocore[crt] >= 1.35.0",
{{#if (eq modelProvider "Bedrock")}}
    "crewai[tools,bedrock] >= 1.3.0",
{{/if}}
{{#if (eq modelProvider "Anthropic")}}
    "crewai[tools,anthropic] >= 1.3.0",
{{/if}}
{{#if (eq modelProvider "OpenAI")}}
    "crewai[tools,openai] >= 1.3.0",
{{/if}}
{{#if (eq modelProvider "Gemini")}}
    "crewai[tools,google-genai] >= 1.3.0",
{{/if}}
]

[tool.hatch.build.targets.wheel]
packages = ["."]
"
`;

exports[`Assets Directory Snapshots > Python framework assets > python/python/googleadk/base/README.md should match snapshot 1`] = `
"This is a project generated by the agentcore create CLI tool!

# Layout

The generated application code lives at the agent root directory. At the root, there is a \`.gitignore\` file, an
\`agentcore/\` folder which represents the configurations and state associated with this project. Other \`agentcore\`
commands like \`deploy\`, \`dev\`, and \`invoke\` rely on the configuration stored here.

## Agent Root

The main entrypoint to your app is defined in \`main.py\`. Using the AgentCore SDK \`@app.entrypoint\` decorator, this
file defines a Starlette ASGI app with the Google ADK framework running within.

\`model/load.py\` instantiates your chosen model provider (Gemini).

## Environment Variables

| Variable | Required | Description |
| --- | --- | --- |
{{#if hasIdentity}}| \`{{identityProviders.[0].envVarName}}\` | Yes | {{modelProvider}} API key (local) or Identity provider name (deployed) |
{{/if}}| \`LOCAL_DEV\` | No | Set to \`1\` to use \`.env.local\` instead of AgentCore Identity |

# Developing locally

If installation was successful, a virtual environment is already created with dependencies installed.

Run \`source .venv/bin/activate\` before developing.

\`agentcore dev\` will start a local server on 0.0.0.0:8080.

In a new terminal, you can invoke that server with:

\`agentcore invoke --dev "What can you do"\`

# Deployment

After providing credentials, \`agentcore deploy\` will deploy your project into Amazon Bedrock AgentCore.

Use \`agentcore invoke\` to invoke your deployed agent.
"
`;

exports[`Assets Directory Snapshots > Python framework assets > python/python/googleadk/base/gitignore.template should match snapshot 1`] = `
"# Environment variables
.env

# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg

# Virtual environments
.venv/
venv/
ENV/
env/

# IDE
.vscode/
.idea/
*.swp
*.swo
*~

# OS
.DS_Store
Thumbs.db
"
`;

exports[`Assets Directory Snapshots > Python framework assets > python/python/googleadk/base/main.py should match snapshot 1`] = `
"import os
from google.adk.agents import Agent
from google.adk.runners import Runner
from google.adk.sessions import InMemorySessionService
from google.genai import types
from bedrock_agentcore.runtime import BedrockAgentCoreApp
from model.load import load_model
from mcp_client.client import get_streamable_http_mcp_client

app = BedrockAgentCoreApp()
log = app.logger

APP_NAME = "{{ name }}"

# https://google.github.io/adk-docs/agents/models/
MODEL_ID = "gemini-2.5-flash"


# Define a simple function tool
def add_numbers(a: int, b: int) -> int:
    """Return the sum of two numbers"""
    return a + b


# Get MCP Toolset
mcp_toolset = [get_streamable_http_mcp_client()]

_credentials_loaded = False

def ensure_credentials_loaded():
    global _credentials_loaded
    if not _credentials_loaded:
        load_model()
        _credentials_loaded = True


# Agent Definition
agent = Agent(
    model=MODEL_ID,
    name="{{ name }}",
    description="Agent to answer questions",
    instruction="I can answer your questions using the knowledge I have!",
    tools=mcp_toolset + [add_numbers],
)


# Session and Runner
async def setup_session_and_runner(user_id, session_id):
    ensure_credentials_loaded()
    session_service = InMemorySessionService()
    session = await session_service.create_session(
        app_name=APP_NAME, user_id=user_id, session_id=session_id
    )
    runner = Runner(agent=agent, app_name=APP_NAME, session_service=session_service)
    return session, runner


# Agent Interaction
async def call_agent_async(query, user_id, session_id):
    content = types.Content(role="user", parts=[types.Part(text=query)])
    session, runner = await setup_session_and_runner(user_id, session_id)
    events = runner.run_async(
        user_id=user_id, session_id=session.id, new_message=content
    )

    final_response = None
    async for event in events:
        if event.is_final_response():
            final_response = event.content.parts[0].text

    return final_response


@app.entrypoint
async def invoke(payload, context):
    log.info("Invoking Agent.....")

    # Process the user prompt
    prompt = payload.get("prompt", "What can you help me with?")
    session_id = getattr(context, "session_id", "default_session")
    user_id = payload.get("user_id", "default_user")

    # Run the agent
    result = await call_agent_async(prompt, user_id, session_id)

    # Return result
    return {"result": result}


if __name__ == "__main__":
    app.run()
"
`;

exports[`Assets Directory Snapshots > Python framework assets > python/python/googleadk/base/mcp_client/__init__.py should match snapshot 1`] = `
"# Package marker
"
`;

exports[`Assets Directory Snapshots > Python framework assets > python/python/googleadk/base/mcp_client/client.py should match snapshot 1`] = `
"from google.adk.tools.mcp_tool.mcp_toolset import MCPToolset
from google.adk.tools.mcp_tool.mcp_session_manager import StreamableHTTPConnectionParams

# ExaAI provides information about code through web searches, crawling and code context searches through their platform. Requires no authentication
EXAMPLE_MCP_ENDPOINT = "https://mcp.exa.ai/mcp"


def get_streamable_http_mcp_client() -> MCPToolset:
    """
    Returns an MCP Toolset compatible with Google ADK.
    """
    # to use an MCP server that supports bearer authentication, add headers={"Authorization": f"Bearer {access_token}"}
    return MCPToolset(
        connection_params=StreamableHTTPConnectionParams(url=EXAMPLE_MCP_ENDPOINT)
    )
"
`;

exports[`Assets Directory Snapshots > Python framework assets > python/python/googleadk/base/model/__init__.py should match snapshot 1`] = `
"# Package marker
"
`;

exports[`Assets Directory Snapshots > Python framework assets > python/python/googleadk/base/model/load.py should match snapshot 1`] = `
"import os
from bedrock_agentcore.identity.auth import requires_api_key

IDENTITY_PROVIDER_NAME = "{{identityProviders.[0].name}}"
IDENTITY_ENV_VAR = "{{identityProviders.[0].envVarName}}"


@requires_api_key(provider_name=IDENTITY_PROVIDER_NAME)
def _agentcore_identity_api_key_provider(api_key: str) -> str:
    """Fetch API key from AgentCore Identity."""
    return api_key


def _get_api_key() -> str:
    """
    Uses AgentCore Identity for API key management in deployed environments.
    For local development, run via 'agentcore dev' which loads agentcore/.env.
    """
    if os.getenv("LOCAL_DEV") == "1":
        api_key = os.getenv(IDENTITY_ENV_VAR)
        if not api_key:
            raise RuntimeError(
                f"{IDENTITY_ENV_VAR} not found. Add {IDENTITY_ENV_VAR}=your-key to .env.local"
            )
        return api_key
    return _agentcore_identity_api_key_provider()


def load_model() -> None:
    """
    Set up Gemini API key authentication.
    Uses AgentCore Identity for API key management in deployed environments,
    and falls back to .env file for local development.
    Sets the GOOGLE_API_KEY environment variable for the Google ADK.
    """
    api_key = _get_api_key()
    # Use Google AI Studios API Key Authentication.
    # https://google.github.io/adk-docs/agents/models/#google-ai-studio
    os.environ["GOOGLE_API_KEY"] = api_key
    # Set to TRUE is using Google Vertex AI, Set to FALSE for Google AI Studio
    os.environ["GOOGLE_GENAI_USE_VERTEXAI"] = "FALSE"
"
`;

exports[`Assets Directory Snapshots > Python framework assets > python/python/googleadk/base/pyproject.toml should match snapshot 1`] = `
"[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[project]
name = "{{ name }}"
version = "0.1.0"
description = "AgentCore Runtime Application using Google ADK"
readme = "README.md"
requires-python = ">=3.10"
dependencies = [
    "opentelemetry-distro",
    "opentelemetry-exporter-otlp",
    "google-adk >= 1.17.0",
    "bedrock-agentcore >= 1.0.3",
    "botocore[crt] >= 1.35.0",
]

[tool.hatch.build.targets.wheel]
packages = ["."]
"
`;

exports[`Assets Directory Snapshots > Python framework assets > python/python/langchain_langgraph/base/README.md should match snapshot 1`] = `
"This is a project generated by the agentcore create CLI tool!

# Layout

The generated application code lives at the agent root directory. At the root, there is a \`.gitignore\` file, an
\`agentcore/\` folder which represents the configurations and state associated with this project. Other \`agentcore\`
commands like \`deploy\`, \`dev\`, and \`invoke\` rely on the configuration stored here.

## Agent Root

The main entrypoint to your app is defined in \`main.py\`. Using the AgentCore SDK \`@app.entrypoint\` decorator, this
file defines a Starlette ASGI app with the LangChain/LangGraph framework running within.

\`model/load.py\` instantiates your chosen model provider.

## Environment Variables

| Variable | Required | Description |
| --- | --- | --- |
{{#if hasIdentity}}| \`{{identityProviders.[0].envVarName}}\` | Yes | {{modelProvider}} API key (local) or Identity provider name (deployed) |
{{/if}}| \`LOCAL_DEV\` | No | Set to \`1\` to use \`.env.local\` instead of AgentCore Identity |

# Developing locally

If installation was successful, a virtual environment is already created with dependencies installed.

Run \`source .venv/bin/activate\` before developing.

\`agentcore dev\` will start a local server on 0.0.0.0:8080.

In a new terminal, you can invoke that server with:

\`agentcore invoke --dev "What can you do"\`

# Deployment

After providing credentials, \`agentcore deploy\` will deploy your project into Amazon Bedrock AgentCore.

Use \`agentcore invoke\` to invoke your deployed agent.
"
`;

exports[`Assets Directory Snapshots > Python framework assets > python/python/langchain_langgraph/base/gitignore.template should match snapshot 1`] = `
"# Environment variables
.env

# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg

# Virtual environments
.venv/
venv/
ENV/
env/

# IDE
.vscode/
.idea/
*.swp
*.swo
*~

# OS
.DS_Store
Thumbs.db
"
`;

exports[`Assets Directory Snapshots > Python framework assets > python/python/langchain_langgraph/base/main.py should match snapshot 1`] = `
"import os
from langchain_core.messages import HumanMessage
from langgraph.prebuilt import create_react_agent
from langchain.tools import tool
from bedrock_agentcore.runtime import BedrockAgentCoreApp
from model.load import load_model
from mcp_client.client import get_streamable_http_mcp_client

app = BedrockAgentCoreApp()
log = app.logger

_llm = None

def get_or_create_model():
    global _llm
    if _llm is None:
        _llm = load_model()
    return _llm


# Define a simple function tool
@tool
def add_numbers(a: int, b: int) -> int:
    """Return the sum of two numbers"""
    return a + b


# Define a collection of tools used by the model
tools = [add_numbers]


@app.entrypoint
async def invoke(payload, context):
    log.info("Invoking Agent.....")

    # Get MCP Client
    mcp_client = get_streamable_http_mcp_client()

    # Load MCP Tools
    mcp_tools = await mcp_client.get_tools()

    # Define the agent using create_react_agent
    graph = create_react_agent(get_or_create_model(), tools=mcp_tools + tools)

    # Process the user prompt
    prompt = payload.get("prompt", "What can you help me with?")

    # Run the agent
    result = await graph.ainvoke({"messages": [HumanMessage(content=prompt)]})

    # Return result
    return {"result": result["messages"][-1].content}


if __name__ == "__main__":
    app.run()
"
`;

exports[`Assets Directory Snapshots > Python framework assets > python/python/langchain_langgraph/base/mcp_client/__init__.py should match snapshot 1`] = `
"# Package marker
"
`;

exports[`Assets Directory Snapshots > Python framework assets > python/python/langchain_langgraph/base/mcp_client/client.py should match snapshot 1`] = `
"from langchain_mcp_adapters.client import MultiServerMCPClient

# ExaAI provides information about code through web searches, crawling and code context searches through their platform. Requires no authentication
EXAMPLE_MCP_ENDPOINT = "https://mcp.exa.ai/mcp"


def get_streamable_http_mcp_client() -> MultiServerMCPClient:
    """
    Returns an MCP Client compatible with LangChain/LangGraph.
    """
    # to use an MCP server that supports bearer authentication, add headers={"Authorization": f"Bearer {access_token}"}
    return MultiServerMCPClient(
        {
            "agentcore_gateway": {
                "transport": "streamable_http",
                "url": EXAMPLE_MCP_ENDPOINT,
            }
        }
    )
"
`;

exports[`Assets Directory Snapshots > Python framework assets > python/python/langchain_langgraph/base/model/__init__.py should match snapshot 1`] = `
"# Package marker
"
`;

exports[`Assets Directory Snapshots > Python framework assets > python/python/langchain_langgraph/base/model/load.py should match snapshot 1`] = `
"{{#if (eq modelProvider "Bedrock")}}
from langchain_aws import ChatBedrock

# Uses global inference profile for Claude Sonnet 4.5
# https://docs.aws.amazon.com/bedrock/latest/userguide/inference-profiles-support.html
MODEL_ID = "global.anthropic.claude-sonnet-4-5-20250929-v1:0"


def load_model() -> ChatBedrock:
    """Get Bedrock model client using IAM credentials."""
    return ChatBedrock(model_id=MODEL_ID)
{{/if}}
{{#if (eq modelProvider "Anthropic")}}
import os
from langchain_anthropic import ChatAnthropic
from bedrock_agentcore.identity.auth import requires_api_key

IDENTITY_PROVIDER_NAME = "{{identityProviders.[0].name}}"
IDENTITY_ENV_VAR = "{{identityProviders.[0].envVarName}}"


@requires_api_key(provider_name=IDENTITY_PROVIDER_NAME)
def _agentcore_identity_api_key_provider(api_key: str) -> str:
    """Fetch API key from AgentCore Identity."""
    return api_key


def _get_api_key() -> str:
    """
    Uses AgentCore Identity for API key management in deployed environments.
    For local development, run via 'agentcore dev' which loads agentcore/.env.
    """
    if os.getenv("LOCAL_DEV") == "1":
        api_key = os.getenv(IDENTITY_ENV_VAR)
        if not api_key:
            raise RuntimeError(
                f"{IDENTITY_ENV_VAR} not found. Add {IDENTITY_ENV_VAR}=your-key to .env.local"
            )
        return api_key
    return _agentcore_identity_api_key_provider()


def load_model() -> ChatAnthropic:
    """Get authenticated Anthropic model client."""
    return ChatAnthropic(
        model="claude-sonnet-4-5-20250929",
        api_key=_get_api_key()
    )
{{/if}}
{{#if (eq modelProvider "OpenAI")}}
import os
from langchain_openai import ChatOpenAI
from bedrock_agentcore.identity.auth import requires_api_key

IDENTITY_PROVIDER_NAME = "{{identityProviders.[0].name}}"
IDENTITY_ENV_VAR = "{{identityProviders.[0].envVarName}}"


@requires_api_key(provider_name=IDENTITY_PROVIDER_NAME)
def _agentcore_identity_api_key_provider(api_key: str) -> str:
    """Fetch API key from AgentCore Identity."""
    return api_key


def _get_api_key() -> str:
    """
    Uses AgentCore Identity for API key management in deployed environments.
    For local development, run via 'agentcore dev' which loads agentcore/.env.
    """
    if os.getenv("LOCAL_DEV") == "1":
        api_key = os.getenv(IDENTITY_ENV_VAR)
        if not api_key:
            raise RuntimeError(
                f"{IDENTITY_ENV_VAR} not found. Add {IDENTITY_ENV_VAR}=your-key to .env.local"
            )
        return api_key
    return _agentcore_identity_api_key_provider()


def load_model() -> ChatOpenAI:
    """Get authenticated OpenAI model client."""
    return ChatOpenAI(
        model="gpt-4.1",
        api_key=_get_api_key()
    )
{{/if}}
{{#if (eq modelProvider "Gemini")}}
import os
from langchain_google_genai import ChatGoogleGenerativeAI
from bedrock_agentcore.identity.auth import requires_api_key

IDENTITY_PROVIDER_NAME = "{{identityProviders.[0].name}}"
IDENTITY_ENV_VAR = "{{identityProviders.[0].envVarName}}"


@requires_api_key(provider_name=IDENTITY_PROVIDER_NAME)
def _agentcore_identity_api_key_provider(api_key: str) -> str:
    """Fetch API key from AgentCore Identity."""
    return api_key


def _get_api_key() -> str:
    """
    Uses AgentCore Identity for API key management in deployed environments.
    For local development, run via 'agentcore dev' which loads agentcore/.env.
    """
    if os.getenv("LOCAL_DEV") == "1":
        api_key = os.getenv(IDENTITY_ENV_VAR)
        if not api_key:
            raise RuntimeError(
                f"{IDENTITY_ENV_VAR} not found. Add {IDENTITY_ENV_VAR}=your-key to .env.local"
            )
        return api_key
    return _agentcore_identity_api_key_provider()


def load_model() -> ChatGoogleGenerativeAI:
    """Get authenticated Gemini model client."""
    return ChatGoogleGenerativeAI(
        model="gemini-2.5-flash",
        api_key=_get_api_key()
    )
{{/if}}
"
`;

exports[`Assets Directory Snapshots > Python framework assets > python/python/langchain_langgraph/base/pyproject.toml should match snapshot 1`] = `
"[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[project]
name = "{{ name }}"
version = "0.1.0"
description = "AgentCore Runtime Application using LangChain/LangGraph"
readme = "README.md"
requires-python = ">=3.10"
dependencies = [
    "opentelemetry-distro",
    "opentelemetry-exporter-otlp",
    "langgraph >= 1.0.2",
    "mcp >= 1.19.0",
    "langchain-mcp-adapters >= 0.1.11",
    "langchain >= 1.0.3",
    "tiktoken == 0.11.0",
    "bedrock-agentcore >= 1.0.3",
    "botocore[crt] >= 1.35.0",
{{#if (eq modelProvider "Bedrock")}}
    "langchain-aws >= 1.0.0",
{{/if}}
{{#if (eq modelProvider "Anthropic")}}
    "langchain-anthropic >= 1.1.0",
{{/if}}
{{#if (eq modelProvider "OpenAI")}}
    "langchain-openai >= 1.0.3",
{{/if}}
{{#if (eq modelProvider "Gemini")}}
    "langchain-google-genai >= 3.0.3",
{{/if}}
]

[tool.hatch.build.targets.wheel]
packages = ["."]
"
`;

exports[`Assets Directory Snapshots > Python framework assets > python/python/openaiagents/base/README.md should match snapshot 1`] = `
"This is a project generated by the agentcore create CLI tool!

# Layout

The generated application code lives at the agent root directory. At the root, there is a \`.gitignore\` file, an
\`agentcore/\` folder which represents the configurations and state associated with this project. Other \`agentcore\`
commands like \`deploy\`, \`dev\`, and \`invoke\` rely on the configuration stored here.

## Agent Root

The main entrypoint to your app is defined in \`main.py\`. Using the AgentCore SDK \`@app.entrypoint\` decorator, this
file defines a Starlette ASGI app with the OpenAI Agents SDK framework running within.

\`model/load.py\` instantiates your chosen model provider (OpenAI).

## Environment Variables

| Variable | Required | Description |
| --- | --- | --- |
{{#if hasIdentity}}| \`{{identityProviders.[0].envVarName}}\` | Yes | {{modelProvider}} API key (local) or Identity provider name (deployed) |
{{/if}}| \`LOCAL_DEV\` | No | Set to \`1\` to use \`.env.local\` instead of AgentCore Identity |

# Developing locally

If installation was successful, a virtual environment is already created with dependencies installed.

Run \`source .venv/bin/activate\` before developing.

\`agentcore dev\` will start a local server on 0.0.0.0:8080.

In a new terminal, you can invoke that server with:

\`agentcore invoke --dev "What can you do"\`

# Deployment

After providing credentials, \`agentcore deploy\` will deploy your project into Amazon Bedrock AgentCore.

Use \`agentcore invoke\` to invoke your deployed agent.
"
`;

exports[`Assets Directory Snapshots > Python framework assets > python/python/openaiagents/base/gitignore.template should match snapshot 1`] = `
"# Environment variables
.env

# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg

# Virtual environments
.venv/
venv/
ENV/
env/

# IDE
.vscode/
.idea/
*.swp
*.swo
*~

# OS
.DS_Store
Thumbs.db
"
`;

exports[`Assets Directory Snapshots > Python framework assets > python/python/openaiagents/base/main.py should match snapshot 1`] = `
"import os
from agents import Agent, Runner, function_tool
from bedrock_agentcore.runtime import BedrockAgentCoreApp
from model.load import load_model
from mcp_client.client import get_streamable_http_mcp_client

app = BedrockAgentCoreApp()
log = app.logger

# Get MCP Server
mcp_server = get_streamable_http_mcp_client()

_credentials_loaded = False

def ensure_credentials_loaded():
    global _credentials_loaded
    if not _credentials_loaded:
        load_model()
        _credentials_loaded = True


# Define a simple function tool
@function_tool
def add_numbers(a: int, b: int) -> int:
    """Return the sum of two numbers"""
    return a + b


# Define the agent execution
async def main(query):
    ensure_credentials_loaded()
    try:
        async with mcp_server as server:
            active_servers = [server] if server else []
            agent = Agent(
                name="{{ name }}",
                model="gpt-4.1",
                mcp_servers=active_servers,
                tools=[add_numbers]
            )
            result = await Runner.run(agent, query)
            return result
    except Exception as e:
        log.error(f"Error during agent execution: {e}", exc_info=True)
        raise e


@app.entrypoint
async def invoke(payload, context):
    log.info("Invoking Agent.....")

    # Process the user prompt
    prompt = payload.get("prompt", "What can you help me with?")

    # Run the agent
    result = await main(prompt)

    # Return result
    return {"result": result.final_output}


if __name__ == "__main__":
    app.run()
"
`;

exports[`Assets Directory Snapshots > Python framework assets > python/python/openaiagents/base/mcp_client/__init__.py should match snapshot 1`] = `
"# Package marker
"
`;

exports[`Assets Directory Snapshots > Python framework assets > python/python/openaiagents/base/mcp_client/client.py should match snapshot 1`] = `
"from agents.mcp import MCPServerStreamableHttp

# ExaAI provides information about code through web searches, crawling and code context searches through their platform. Requires no authentication
EXAMPLE_MCP_ENDPOINT = "https://mcp.exa.ai/mcp"


def get_streamable_http_mcp_client() -> MCPServerStreamableHttp:
    """
    Returns an MCP Client compatible with OpenAI Agents SDK.
    """
    # to use an MCP server that supports bearer authentication, add headers={"Authorization": f"Bearer {access_token}"}
    return MCPServerStreamableHttp(
        name="AgentCore Gateway MCP", params={"url": EXAMPLE_MCP_ENDPOINT}
    )
"
`;

exports[`Assets Directory Snapshots > Python framework assets > python/python/openaiagents/base/model/__init__.py should match snapshot 1`] = `
"# Package marker
"
`;

exports[`Assets Directory Snapshots > Python framework assets > python/python/openaiagents/base/model/load.py should match snapshot 1`] = `
"import os
from bedrock_agentcore.identity.auth import requires_api_key

IDENTITY_PROVIDER_NAME = "{{identityProviders.[0].name}}"
IDENTITY_ENV_VAR = "{{identityProviders.[0].envVarName}}"


@requires_api_key(provider_name=IDENTITY_PROVIDER_NAME)
def _agentcore_identity_api_key_provider(api_key: str) -> str:
    """Fetch API key from AgentCore Identity."""
    return api_key


def _get_api_key() -> str:
    """
    Uses AgentCore Identity for API key management in deployed environments.
    For local development, run via 'agentcore dev' which loads agentcore/.env.
    """
    if os.getenv("LOCAL_DEV") == "1":
        api_key = os.getenv(IDENTITY_ENV_VAR)
        if not api_key:
            raise RuntimeError(
                f"{IDENTITY_ENV_VAR} not found. Add {IDENTITY_ENV_VAR}=your-key to .env.local"
            )
        return api_key
    return _agentcore_identity_api_key_provider()


def load_model() -> None:
    """
    Set up OpenAI API key authentication.
    Uses AgentCore Identity for API key management in deployed environments,
    and falls back to .env file for local development.
    Sets the OPENAI_API_KEY environment variable for the OpenAI Agents SDK.
    """
    api_key = _get_api_key()
    os.environ["OPENAI_API_KEY"] = api_key if api_key else ""
"
`;

exports[`Assets Directory Snapshots > Python framework assets > python/python/openaiagents/base/pyproject.toml should match snapshot 1`] = `
"[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[project]
name = "{{ name }}"
version = "0.1.0"
description = "AgentCore Runtime Application using OpenAI Agents SDK"
readme = "README.md"
requires-python = ">=3.10"
dependencies = [
    "aws-opentelemetry-distro",
    "openai-agents >= 0.4.2",
    "bedrock-agentcore >= 1.0.3",
    "botocore[crt] >= 1.35.0",
]

[tool.hatch.build.targets.wheel]
packages = ["."]
"
`;

exports[`Assets Directory Snapshots > Python framework assets > python/python/strands/base/README.md should match snapshot 1`] = `
"This is a project generated by the agentcore create CLI tool!

# Layout

The generated application code lives at the agent root directory. At the root, there is a \`.gitignore\` file, an
\`agentcore/\` folder which represents the configurations and state associated with this project. Other \`agentcore\`
commands like \`deploy\`, \`dev\`, and \`invoke\` rely on the configuration stored here.

## Agent Root

The main entrypoint to your app is defined in \`main.py\`. Using the AgentCore SDK \`@app.entrypoint\` decorator, this
file defines a Starlette ASGI app with the chosen Agent framework SDK running within.

\`model/load.py\` instantiates your chosen model provider.

## Environment Variables

| Variable | Required | Description |
| --- | --- | --- |
{{#if hasIdentity}}| \`{{identityProviders.[0].envVarName}}\` | Yes | {{modelProvider}} API key (local) or Identity provider name (deployed) |
{{/if}}| \`LOCAL_DEV\` | No | Set to \`1\` to use \`.env.local\` instead of AgentCore Identity |

# Developing locally

If installation was successful, a virtual environment is already created with dependencies installed.

Run \`source .venv/bin/activate\` before developing.

\`agentcore dev\` will start a local server on 0.0.0.0:8080.

In a new terminal, you can invoke that server with:

\`agentcore invoke --dev "What can you do"\`

# Deployment

After providing credentials, \`agentcore deploy\` will deploy your project into Amazon Bedrock AgentCore.

Use \`agentcore invoke\` to invoke your deployed agent.
"
`;

exports[`Assets Directory Snapshots > Python framework assets > python/python/strands/base/gitignore.template should match snapshot 1`] = `
"# Environment variables
.env

# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg

# Virtual environments
.venv/
venv/
ENV/
env/

# IDE
.vscode/
.idea/
*.swp
*.swo
*~

# OS
.DS_Store
Thumbs.db"
`;

exports[`Assets Directory Snapshots > Python framework assets > python/python/strands/base/main.py should match snapshot 1`] = `
"from strands import Agent, tool
from bedrock_agentcore.runtime import BedrockAgentCoreApp
from model.load import load_model
from mcp_client.client import get_streamable_http_mcp_client
{{#if hasMemory}}
from memory.session import get_memory_session_manager
{{/if}}

app = BedrockAgentCoreApp()
log = app.logger

# Define a Streamable HTTP MCP Client
mcp_client = get_streamable_http_mcp_client()

# Define a collection of tools used by the model
tools = []

# Define a simple function tool
@tool
def add_numbers(a: int, b: int) -> int:
    """Return the sum of two numbers"""
    return a+b
tools.append(add_numbers)


{{#if hasMemory}}
def agent_factory():
    cache = {}
    def get_or_create_agent(session_id, user_id):
        key = f"{session_id}/{user_id}"
        if key not in cache:
            # Create an agent for the given session_id and user_id
            cache[key] = Agent(
                model=load_model(),
                session_manager=get_memory_session_manager(session_id, user_id),
                system_prompt="""
                    You are a helpful assistant. Use tools when appropriate.
                """,
                tools=tools+[mcp_client]
            )
        return cache[key]
    return get_or_create_agent
get_or_create_agent = agent_factory()
{{else}}
_agent = None

def get_or_create_agent():
    global _agent
    if _agent is None:
        _agent = Agent(
            model=load_model(),
            system_prompt="""
                You are a helpful assistant. Use tools when appropriate.
            """,
            tools=tools+[mcp_client]
        )
    return _agent
{{/if}}


@app.entrypoint
async def invoke(payload, context):
    log.info("Invoking Agent.....")

{{#if hasMemory}}
    session_id = getattr(context, 'session_id', 'default-session')
    user_id = getattr(context, 'user_id', 'default-user')
    agent = get_or_create_agent(session_id, user_id)
{{else}}
    agent = get_or_create_agent()
{{/if}}

    # Execute and format response
    stream = agent.stream_async(payload.get("prompt"))

    async for event in stream:
        # Handle Text parts of the response
        if "data" in event and isinstance(event["data"], str):
            yield event["data"]


if __name__ == "__main__":
    app.run()
"
`;

exports[`Assets Directory Snapshots > Python framework assets > python/python/strands/base/mcp_client/__init__.py should match snapshot 1`] = `
"# Package marker
"
`;

exports[`Assets Directory Snapshots > Python framework assets > python/python/strands/base/mcp_client/client.py should match snapshot 1`] = `
"from mcp.client.streamable_http import streamablehttp_client
from strands.tools.mcp.mcp_client import MCPClient

# ExaAI provides information about code through web searches, crawling and code context searches through their platform. Requires no authentication
EXAMPLE_MCP_ENDPOINT = "https://mcp.exa.ai/mcp"

def get_streamable_http_mcp_client() -> MCPClient:
    """
    Returns an MCP Client compatible with Strands
    """
    # to use an MCP server that supports bearer authentication, add headers={"Authorization": f"Bearer {access_token}"}
    return MCPClient(lambda: streamablehttp_client(EXAMPLE_MCP_ENDPOINT))"
`;

exports[`Assets Directory Snapshots > Python framework assets > python/python/strands/base/model/__init__.py should match snapshot 1`] = `
"# Package marker
"
`;

exports[`Assets Directory Snapshots > Python framework assets > python/python/strands/base/model/load.py should match snapshot 1`] = `
"{{#if (eq modelProvider "Bedrock")}}
from strands.models.bedrock import BedrockModel


def load_model() -> BedrockModel:
    """Get Bedrock model client using IAM credentials."""
    return BedrockModel(model_id="global.anthropic.claude-sonnet-4-5-20250929-v1:0")
{{/if}}
{{#if (eq modelProvider "Anthropic")}}
import os

from strands.models.anthropic import AnthropicModel
from bedrock_agentcore.identity.auth import requires_api_key

IDENTITY_PROVIDER_NAME = "{{identityProviders.[0].name}}"
IDENTITY_ENV_VAR = "{{identityProviders.[0].envVarName}}"


@requires_api_key(provider_name=IDENTITY_PROVIDER_NAME)
def _agentcore_identity_api_key_provider(api_key: str) -> str:
    """Fetch API key from AgentCore Identity."""
    return api_key


def _get_api_key() -> str:
    """
    Uses AgentCore Identity for API key management in deployed environments.
    For local development, run via 'agentcore dev' which loads agentcore/.env.
    """
    if os.getenv("LOCAL_DEV") == "1":
        api_key = os.getenv(IDENTITY_ENV_VAR)
        if not api_key:
            raise RuntimeError(
                f"{IDENTITY_ENV_VAR} not found. Add {IDENTITY_ENV_VAR}=your-key to .env.local"
            )
        return api_key
    return _agentcore_identity_api_key_provider()


def load_model() -> AnthropicModel:
    """Get authenticated Anthropic model client."""
    return AnthropicModel(
        client_args={"api_key": _get_api_key()},
        model_id="claude-sonnet-4-5-20250929",
        max_tokens=5000,
    )
{{/if}}
{{#if (eq modelProvider "OpenAI")}}
import os

from strands.models.openai import OpenAIModel
from bedrock_agentcore.identity.auth import requires_api_key

IDENTITY_PROVIDER_NAME = "{{identityProviders.[0].name}}"
IDENTITY_ENV_VAR = "{{identityProviders.[0].envVarName}}"


@requires_api_key(provider_name=IDENTITY_PROVIDER_NAME)
def _agentcore_identity_api_key_provider(api_key: str) -> str:
    """Fetch API key from AgentCore Identity."""
    return api_key


def _get_api_key() -> str:
    """
    Uses AgentCore Identity for API key management in deployed environments.
    For local development, run via 'agentcore dev' which loads agentcore/.env.
    """
    if os.getenv("LOCAL_DEV") == "1":
        api_key = os.getenv(IDENTITY_ENV_VAR)
        if not api_key:
            raise RuntimeError(
                f"{IDENTITY_ENV_VAR} not found. Add {IDENTITY_ENV_VAR}=your-key to .env.local"
            )
        return api_key
    return _agentcore_identity_api_key_provider()


def load_model() -> OpenAIModel:
    """Get authenticated OpenAI model client."""
    return OpenAIModel(
        client_args={"api_key": _get_api_key()},
        model_id="gpt-4.1",
    )
{{/if}}
{{#if (eq modelProvider "Gemini")}}
import os

from strands.models.gemini import GeminiModel
from bedrock_agentcore.identity.auth import requires_api_key

IDENTITY_PROVIDER_NAME = "{{identityProviders.[0].name}}"
IDENTITY_ENV_VAR = "{{identityProviders.[0].envVarName}}"


@requires_api_key(provider_name=IDENTITY_PROVIDER_NAME)
def _agentcore_identity_api_key_provider(api_key: str) -> str:
    """Fetch API key from AgentCore Identity."""
    return api_key


def _get_api_key() -> str:
    """
    Uses AgentCore Identity for API key management in deployed environments.
    For local development, run via 'agentcore dev' which loads agentcore/.env.
    """
    if os.getenv("LOCAL_DEV") == "1":
        api_key = os.getenv(IDENTITY_ENV_VAR)
        if not api_key:
            raise RuntimeError(
                f"{IDENTITY_ENV_VAR} not found. Add {IDENTITY_ENV_VAR}=your-key to .env.local"
            )
        return api_key
    return _agentcore_identity_api_key_provider()


def load_model() -> GeminiModel:
    """Get authenticated Gemini model client."""
    return GeminiModel(
        client_args={"api_key": _get_api_key()},
        model_id="gemini-2.5-flash",
    )
{{/if}}
"
`;

exports[`Assets Directory Snapshots > Python framework assets > python/python/strands/base/pyproject.toml should match snapshot 1`] = `
"[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[project]
name = "{{ name }}"
version = "0.1.0"
description = "AgentCore Runtime Application using Strands SDK"
readme = "README.md"
requires-python = ">=3.10"
dependencies = [
    {{#if (eq modelProvider "Anthropic")}}"anthropic >= 0.30.0",
    {{/if}}"aws-opentelemetry-distro",
    "bedrock-agentcore >= 1.0.3",
    "botocore[crt] >= 1.35.0",
    {{#if (eq modelProvider "Gemini")}}"google-genai >= 1.0.0",
    {{/if}}"mcp >= 1.19.0",
    {{#if (eq modelProvider "OpenAI")}}"openai >= 1.0.0",
    {{/if}}"strands-agents >= 1.13.0",
]

[tool.hatch.build.targets.wheel]
packages = ["."]
"
`;

exports[`Assets Directory Snapshots > Python framework assets > python/python/strands/capabilities/memory/__init__.py should match snapshot 1`] = `
"# Package marker
"
`;

exports[`Assets Directory Snapshots > Python framework assets > python/python/strands/capabilities/memory/session.py should match snapshot 1`] = `
"import os
from typing import Optional

from bedrock_agentcore.memory.integrations.strands.config import AgentCoreMemoryConfig{{#if memoryProviders.[0].strategies.length}}, RetrievalConfig{{/if}}
from bedrock_agentcore.memory.integrations.strands.session_manager import AgentCoreMemorySessionManager

MEMORY_ID = os.getenv("{{memoryProviders.[0].envVarName}}")
REGION = os.getenv("AWS_REGION")

def get_memory_session_manager(session_id: str, actor_id: str) -> Optional[AgentCoreMemorySessionManager]:
    if not MEMORY_ID:
        return None

{{#if memoryProviders.[0].strategies.length}}
    retrieval_config = {
{{#if (includes memoryProviders.[0].strategies "SEMANTIC")}}
        f"/users/{actor_id}/facts": RetrievalConfig(top_k=3, relevance_score=0.5),
{{/if}}
{{#if (includes memoryProviders.[0].strategies "USER_PREFERENCE")}}
        f"/users/{actor_id}/preferences": RetrievalConfig(top_k=3, relevance_score=0.5),
{{/if}}
{{#if (includes memoryProviders.[0].strategies "SUMMARIZATION")}}
        f"/summaries/{actor_id}/{session_id}": RetrievalConfig(top_k=3, relevance_score=0.5),
{{/if}}
    }
{{/if}}

    return AgentCoreMemorySessionManager(
        AgentCoreMemoryConfig(
            memory_id=MEMORY_ID,
            session_id=session_id,
            actor_id=actor_id,
{{#if memoryProviders.[0].strategies.length}}
            retrieval_config=retrieval_config,
{{/if}}
        ),
        REGION
    )

"
`;

exports[`Assets Directory Snapshots > Root-level assets > AGENTS.md should match snapshot 1`] = `
"## AgentCore Templates

This directory stores:

- Template assets for agents written in different Languages, SDKs and having different configurations
- Container templates (\`container/python/\`) with \`Dockerfile\` and \`.dockerignore\` for Container build agents

### Directory Layout

\`\`\`
assets/
├── python/              # Framework templates (one per SDK)
│   ├── strands/
│   ├── langchain_langgraph/
│   ├── crewai/
│   ├── googleadk/
│   ├── openaiagents/
│   └── autogen/
├── container/           # Container build templates
│   └── python/
│       ├── Dockerfile
│       └── dockerignore.template
└── agents/              # AGENTS.md vended to user projects
\`\`\`

The rendering logic is rooted in the \`AgentEnvSpec\` and must ALWAYS respect the configuration in the Spec.

For Container builds, \`BaseRenderer.render()\` automatically copies the \`container/<language>/\` templates (Dockerfile,
.dockerignore) into the agent directory when \`buildType === 'Container'\`.

## Guidance for template changes

- Always make sure the templates are as close to working code as possible
- AVOID as much as possible using any conditionals within the templates

## How to use the assets in this directory

- These assets are rendered by the CLI's template renderer in \`src/cli/templates/\`.
"
`;

exports[`Assets Directory Snapshots > Root-level assets > README.md should match snapshot 1`] = `
"# AgentCore Project

This project was created with the [AgentCore CLI](https://github.com/aws/agentcore-cli).

## Project Structure

\`\`\`
.
my-project/
├── agentcore/
│   ├── .env.local          # API keys (gitignored)
│   ├── agentcore.json      # Resource specifications
│   ├── aws-targets.json    # Deployment targets
│   └── cdk/                # CDK infrastructure
├── app/                    # Application code
\`\`\`

## Getting Started

### Prerequisites

- **Node.js** 20.x or later
- **uv** for Python agents ([install](https://docs.astral.sh/uv/getting-started/installation/))

### Development

Run your agent locally:

\`\`\`bash
agentcore dev
\`\`\`

### Deployment

Deploy to AWS:

\`\`\`bash
agentcore deploy
\`\`\`

Or use CDK directly:

\`\`\`bash
cd agentcore/cdk
npx cdk deploy
\`\`\`

## Configuration

Edit the JSON files in \`agentcore/\` to configure your agents, memory, and credentials. See \`agentcore/.llm-context/\` for
type definitions and validation constraints.

The project uses a **flat resource model** where agents, memories, and credentials are top-level arrays in
\`agentcore.json\`.

## Commands

| Command              | Description                                     |
| -------------------- | ----------------------------------------------- |
| \`agentcore create\`   | Create a new AgentCore project                  |
| \`agentcore add\`      | Add resources (agent, memory, identity, target) |
| \`agentcore remove\`   | Remove resources                                |
| \`agentcore dev\`      | Run agent locally                               |
| \`agentcore deploy\`   | Deploy to AWS                                   |
| \`agentcore status\`   | Show deployment status                          |
| \`agentcore invoke\`   | Invoke agent (local or deployed)                |
| \`agentcore package\`  | Package agent artifacts                         |
| \`agentcore validate\` | Validate configuration                          |
| \`agentcore update\`   | Check for CLI updates                           |

### Agent Types

- **Template agents**: Created from framework templates (Strands, LangChain_LangGraph, GoogleADK, OpenAIAgents)
- **BYO agents**: Bring your own code with \`agentcore add agent --type byo\`

## Documentation

- [AgentCore CLI Documentation](https://github.com/aws/agentcore-cli)
- [Amazon Bedrock AgentCore](https://aws.amazon.com/bedrock/agentcore/)
"
`;

exports[`Assets Directory Snapshots > Root-level assets > agents/AGENTS.md should match snapshot 1`] = `
"# AgentCore Project

This project contains configuration and infrastructure for an Amazon Bedrock AgentCore application.

The \`agentcore/\` directory serves as a declarative model of an AgentCore project along with a concrete implementation
through the \`agentcore/cdk/\` project which is modeled to take the configs as input. The project uses a **flat resource
model** where agents, memories, and credentials are top-level arrays.

## Mental Model

The project uses a **flat resource model**. Agents, memories, and credentials are independent top-level arrays in
\`agentcore.json\`. There is no binding or attachment between resources in the schema — each resource is provisioned
independently. To use a memory or credential from an agent, the application code discovers the resource at runtime
(e.g., via environment variables or SDK calls).

## Critical Invariants

1. **Schema-First Authority:** The \`.json\` files are the absolute source of truth. Do not attempt to modify agent
   behavior by editing the generated CDK code in \`cdk/\`.
2. **Resource Identity:** The \`name\` field in the schema determines the CloudFormation Logical ID.
   - **Renaming** an agent or target will **destroy and recreate** that resource.
   - **Modifying** other fields (descriptions, config) will update the resource **in-place**.
3. **1:1 Validation:** The schema maps directly to valid CloudFormation. If your JSON conforms to the types in
   \`.llm-context/\`, it will deploy successfully.
4. **Resource Removal:** To remove all resources, use \`agentcore remove all\`. To tear down deployed infrastructure, run
   \`agentcore deploy\` after removal — it will detect the empty state and offer a teardown flow.

## Directory Structure

\`\`\`
myNewProject/
├── AGENTS.md               # This file - AI coding assistant context
├── agentcore/              # AgentCore configuration directory
│   ├── agentcore.json      # Main project config (AgentCoreProjectSpec)
│   ├── aws-targets.json    # Deployment targets
│   ├── .llm-context/       # TypeScript type definitions for AI coding assistants
│   │   ├── README.md       # Guide to using the schema files
│   │   ├── agentcore.ts    # AgentCoreProjectSpec types
│   │   └── aws-targets.ts  # AWS deployment target types
│   └── cdk/                # AWS CDK project for deployment
└── app/                    # Application code (if agents were created)
\`\`\`

## Schema Reference

The \`agentcore/.llm-context/\` directory contains TypeScript type definitions optimized for AI coding assistants. Each
file maps to a JSON config file and includes validation constraints as comments.

| JSON Config                  | Schema File                             | Root Type               |
| ---------------------------- | --------------------------------------- | ----------------------- |
| \`agentcore/agentcore.json\`   | \`agentcore/.llm-context/agentcore.ts\`   | \`AgentCoreProjectSpec\`  |
| \`agentcore/aws-targets.json\` | \`agentcore/.llm-context/aws-targets.ts\` | \`AWSDeploymentTarget[]\` |

### Key Types

- **AgentCoreProjectSpec**: Root project configuration with \`agents\`, \`memories\`, \`credentials\` arrays
- **AgentEnvSpec**: Agent configuration (runtime, entrypoint, code location)
- **Memory**: Memory resource with strategies and expiry
- **Credential**: API key credential provider

### Common Enum Values

- **BuildType**: \`'CodeZip'\` | \`'Container'\`
- **NetworkMode**: \`'PUBLIC'\`
- **RuntimeVersion**: \`'PYTHON_3_10'\` | \`'PYTHON_3_11'\` | \`'PYTHON_3_12'\` | \`'PYTHON_3_13'\`
- **MemoryStrategyType**: \`'SEMANTIC'\` | \`'SUMMARIZATION'\` | \`'USER_PREFERENCE'\`

### Build Types

- **CodeZip**: Python source is packaged as a zip artifact and deployed directly to AgentCore Runtime.
- **Container**: Agent code is built as a Docker container image. Requires a \`Dockerfile\` in the agent's \`codeLocation\`
  directory. At deploy time, the source is uploaded to S3, built in CodeBuild (ARM64), pushed to a per-agent ECR
  repository, and the container URI is provided to the AgentCore Runtime. For local development (\`agentcore dev\`), the
  container is built and run locally with volume-mounted hot-reload.

### Supported Frameworks (for template agents)

- **Strands** - Works with Bedrock, Anthropic, OpenAI, Gemini
- **LangChain_LangGraph** - Works with Bedrock, Anthropic, OpenAI, Gemini
- **CrewAI** - Works with Bedrock, Anthropic, OpenAI, Gemini
- **GoogleADK** - Gemini only
- **OpenAIAgents** - OpenAI only
- **AutoGen** - Works with Bedrock, Anthropic, OpenAI, Gemini

### Specific Context

Directory pathing to local projects is required for runtimes. Both CodeZip (Python zip) and Container (Docker image)
deployment options are available.

## Deployment

The \`agentcore/cdk/\` subdirectory contains an AWS CDK node project.

Deployments of this project are primarily intended to be orchestrated through the \`agentcore deploy\` command in the CLI.

Alternatively, the project can be deployed directly as a traditional CDK project:

\`\`\`bash
cd agentcore/cdk
npm install
npx cdk synth   # Preview CloudFormation template
npx cdk deploy  # Deploy to AWS
\`\`\`

## Editing Schemas

When modifying JSON config files:

1. Read the corresponding \`agentcore/.llm-context/*.ts\` file for type definitions
2. Check validation constraint comments (\`@regex\`, \`@min\`, \`@max\`)
3. Use exact enum values as string literals
4. Use CloudFormation-safe names (alphanumeric, start with letter)
5. Run \`agentcore validate\` command to verify changes.
"
`;

exports[`Assets Directory Snapshots > TypeScript assets > typescript/typescript/.gitkeep should match snapshot 1`] = `""`;
